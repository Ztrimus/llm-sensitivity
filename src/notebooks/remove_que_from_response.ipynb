{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136400, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the directory containing the datasets\n",
    "data_dir = \"../../data/\"\n",
    "dataset_path = os.path.join(data_dir, \"analyzed/catHarmQA/combined_catqa.csv\")\n",
    "\n",
    "data = pd.read_csv(dataset_path)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'subcategory', 'original_question',\n",
       "       'original_question_safety', 'original_response',\n",
       "       'original_response_safety', 'original_response_pre',\n",
       "       'original_response_pre_safety', 'experiment', 'perturbation_level',\n",
       "       'perturbation_type', 'perturbation_count', 'perturbed_question',\n",
       "       'perturbed_question_safety', 'model', 'perturbed_response',\n",
       "       'perturbed_response_safety', 'perturbed_response_pre',\n",
       "       'perturbed_response_pre_safety'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text in \"orignal_response\" column start with question which from \"original_question\" columns and It's not needed, so we have to remove that question. so, we check if question from \"original_question\" match with start portion of \"orignal_response\" then remove that question from \"orignal_response\" column. same will happen with \"perturbed_response\" column which have question from \"perturbed_question\" column. remember that data variable is pandas dataframe and we can access columns by their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_eage_case(content):\n",
    "    # edge cases\n",
    "    for condition in [\" ' \", \" '\", \" !\", \" ,\", \" ?\", \" .\", \" '\"]:\n",
    "        if condition in content:\n",
    "            content = content.replace(condition, condition.strip())\n",
    "        # content = re.sub(r\"\\s*'\\s*\", \"'\", content)\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "# Function to remove question from response\n",
    "def remove_question_from_response(row, question_col, response_col, handle_edge_case_condition=False):\n",
    "    question = row[question_col] if not handle_edge_case_condition else handle_eage_case(row[question_col])\n",
    "    response = row[response_col] if not handle_edge_case_condition else handle_eage_case(row[response_col])\n",
    "    if response.startswith(question):\n",
    "        return response[len(question) :].strip()\n",
    "    else:\n",
    "        if handle_edge_case_condition and not response.startswith(question):\n",
    "            print(f\"{row.name}th row\")\n",
    "            print(f\"question: {question}\")\n",
    "            print(f\"response: {response}\", f\"\\n{'-'*120}\\n\")      \n",
    "            return response\n",
    "        else:\n",
    "            return remove_question_from_response(row, question_col, response_col, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to both original and perturbed columns\n",
    "data[\"original_response_pre\"] = data.apply(\n",
    "    lambda row: remove_question_from_response(\n",
    "        row, \"original_question\", \"original_response\"\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "data[\"perturbed_response_pre\"] = data.apply(\n",
    "    lambda row: remove_question_from_response(\n",
    "        row, \"perturbed_question\", \"perturbed_response\"\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test if prefix question is removed from \"original_response\" and \"perturbed_response\" columns. we will do that by coding. we will take difference between \"original_response_pre\" and \"original_response\", it will output text from \"original_response\" which is not in \"original_response_pre\" and different will be equal to \"original_question\". so perform this check over all rows and return count of False. we will do same for \"perturbed_response_pre\" and \"perturbed_response\" columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_common_substring(A, B):\n",
    "    index = A.find(B)\n",
    "    if index == -1:\n",
    "        return A\n",
    "    else:\n",
    "        return A[:index]\n",
    "\n",
    "# Function to check if the prefix question is removed\n",
    "def check_prefix_removed(row, question_col, response_pre_col, response_col, handle_edge_case_condition=False):\n",
    "    question = row[question_col] if not handle_edge_case_condition else handle_eage_case(row[question_col])\n",
    "    response = row[response_col] if not handle_edge_case_condition else handle_eage_case(row[response_col])\n",
    "    response_pre = row[response_pre_col]\n",
    "\n",
    "    non_common_substring = find_non_common_substring(response, response_pre).strip()\n",
    "\n",
    "    if non_common_substring.strip() == question.strip():\n",
    "        return True\n",
    "    else:\n",
    "        if handle_edge_case_condition and non_common_substring.strip() != question.strip():\n",
    "            # print(f\"{row.name}th row\")\n",
    "            # print(f\"question: {question}\")\n",
    "            # print(f\"response: {response}\")\n",
    "            # print(f\"resp_pre: {response_pre}\", f\"\\n{'-'*120}\\n\")\n",
    "            return question.__contains__(non_common_substring)\n",
    "        else:\n",
    "            return check_prefix_removed(row, question_col, response_pre_col, response_col, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the check function to both original and perturbed columns\n",
    "original_check = data.apply(\n",
    "    lambda row: check_prefix_removed(\n",
    "        row, \"original_question\", \"original_response_pre\", \"original_response\"\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "perturbed_check = data.apply(\n",
    "    lambda row: check_prefix_removed(\n",
    "        row, \"perturbed_question\", \"perturbed_response_pre\", \"perturbed_response\"\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check and Validation of above Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all rows satisfy `original_question + original_response_pre == original_response`\n",
    "original_check.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all rows satisfy `perturbed_question + perturbed_response_pre == perturbed_response`\n",
    "perturbed_check.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of False for perturbed_response: 0\n"
     ]
    }
   ],
   "source": [
    "perturbed_false_count = len(perturbed_check) - perturbed_check.sum()\n",
    "print(f\"Count of False for perturbed_response: {perturbed_false_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: bool)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbed_check[perturbed_check == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perturbed_response_pre == perturbed_response: \n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"perturbed_response_pre == perturbed_response: \\n{perturbed_check[perturbed_check == False].index.to_series().apply(lambda x: data.loc[x, \"perturbed_response_pre\"] == data.loc[x, \"perturbed_response\"]).value_counts()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: count, dtype: int64)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbed_check[perturbed_check == False].index.to_series().apply(lambda x: data.loc[x, \"model\"]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in perturbed_check[perturbed_check == False].index:\n",
    "    print(\"------ \", data.loc[index, \"perturbed_question\"], \"\\n\")\n",
    "    print(\"------ \", data.loc[index, \"perturbed_response\"], \"\\n\")\n",
    "    print(\"------ \", data.loc[index, \"perturbed_response_pre\"], \"\\n\")\n",
    "    print(data.loc[index, \"perturbed_response_pre\"] == data.loc[index, \"perturbed_response\"], \"\\n\")\n",
    "    print(f\"{'-'*120}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv(dataset_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess safety response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_1 = os.path.join(data_dir, \"analyzed/catHarmQA/combined_catqa1.csv\")\n",
    "dataset_path_2 = os.path.join(data_dir, \"analyzed/catHarmQA/combined_catqa2.csv\")\n",
    "\n",
    "data1 = pd.read_csv(dataset_path_1)\n",
    "data2 = pd.read_csv(dataset_path_2)\n",
    "\n",
    "# for column in ['category', 'subcategory', 'original_question', 'original_question_safety', 'original_response', 'original_response_safety', 'perturbation_level', 'perturbation_type', 'perturbed_question', 'perturbed_question_safety', 'model', 'perturbed_response', 'perturbed_response_safety', 'experiment', 'original_response_pre', 'original_response_pre_safety', 'perturbed_response_pre', 'perturbed_response_pre_safety']:\n",
    "#     data1[column] = data1[column].astype('string')\n",
    "#     data2[column] = data2[column].astype('string')\n",
    "\n",
    "# data1.to_csv(dataset_path_1, index=False)\n",
    "# data2.to_csv(dataset_path_2, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis - After removing questions from response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'subcategory', 'original_question',\n",
       "       'original_question_safety', 'original_response',\n",
       "       'original_response_safety', 'perturbation_level', 'perturbation_type',\n",
       "       'perturbation_count', 'perturbed_question', 'perturbed_question_safety',\n",
       "       'model', 'perturbed_response', 'perturbed_response_safety',\n",
       "       'experiment', 'original_response_pre', 'perturbed_response_pre'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv(dataset_path_2, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "perturbed_response_pre_safety\n",
       "safe      92586\n",
       "unsafe    43814\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.perturbed_response_pre_safety.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of changed rows: 59206\n"
     ]
    }
   ],
   "source": [
    "changed_rows = data[\n",
    "    data[\"perturbed_response_safety\"] != data[\"perturbed_response_pre_safety\"]\n",
    "]\n",
    "num_changed = changed_rows.shape[0]\n",
    "print(f\"Number of changed rows: {num_changed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of changed rows: 43.41%\n"
     ]
    }
   ],
   "source": [
    "percentage_changed = (num_changed / len(data)) * 100\n",
    "print(f\"Percentage of changed rows: {percentage_changed:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_question_safety\n",
       "unsafe    0.932727\n",
       "safe      0.067273\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.original_question_safety.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
