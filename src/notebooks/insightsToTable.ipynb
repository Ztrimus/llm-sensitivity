{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the directory containing the datasets\n",
    "data_dir = \"../../data/\"\n",
    "dataset_path = os.path.join(data_dir, \"analyzed/catHarmQA/combined_catqa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Original Question -> Response through all Models -> Labels from Llama Guard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>original_response_safety</th>\n",
       "      <th>safe</th>\n",
       "      <th>unsafe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>llama2</th>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama31</th>\n",
       "      <td>0.216364</td>\n",
       "      <td>0.783636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral</th>\n",
       "      <td>0.176364</td>\n",
       "      <td>0.823636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "original_response_safety      safe    unsafe\n",
       "model                                       \n",
       "llama2                    0.320000  0.680000\n",
       "llama3                    0.180000  0.820000\n",
       "llama31                   0.216364  0.783636\n",
       "mistral                   0.176364  0.823636"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of safe and unsafe responses of each model for original questions\n",
    "data.groupby(\"model\")[\"original_response_safety\"].value_counts(normalize=True).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Cross verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unsafe</th>\n",
       "      <th>safe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>llama2</th>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3</th>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama31</th>\n",
       "      <td>0.783636</td>\n",
       "      <td>0.216364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral</th>\n",
       "      <td>0.823636</td>\n",
       "      <td>0.176364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           unsafe      safe\n",
       "llama2   0.680000  0.320000\n",
       "llama3   0.820000  0.180000\n",
       "llama31  0.783636  0.216364\n",
       "mistral  0.823636  0.176364"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a helper function to filter the safety responses\n",
    "def filter_safety_response(label):\n",
    "    return label.strip().split()[0].lower()\n",
    "\n",
    "# Load individual model safety data\n",
    "llama2_org_ques_safety_df = pd.read_csv(os.path.join(data_dir, \"safety/catHarmQA/response/catqa_llama2_Question_safety.csv\"))\n",
    "llama3_org_ques_safety_df = pd.read_csv(os.path.join(data_dir, \"safety/catHarmQA/response/catqa_llama3_Question_safety.csv\"))\n",
    "llama31_org_ques_safety_df = pd.read_csv(os.path.join(data_dir, \"safety/catHarmQA/response/catqa_llama31_Question_safety.csv\"))\n",
    "mistral_org_ques_safety_df = pd.read_csv(os.path.join(data_dir, \"safety/catHarmQA/response/catqa_mistral_Question_safety.csv\"))\n",
    "\n",
    "# Apply filtering and calculate normalized proportions for each model\n",
    "pd.DataFrame({\n",
    "            \"llama2\": llama2_org_ques_safety_df['Question_llama2_safety'].apply(filter_safety_response).value_counts(normalize=True),\n",
    "            \"llama3\": llama3_org_ques_safety_df['Question_llama3_safety'].apply(filter_safety_response).value_counts(normalize=True),\n",
    "            \"llama31\": llama31_org_ques_safety_df['Question_llama31_safety'].apply(filter_safety_response).value_counts(normalize=True),\n",
    "            \"mistral\": mistral_org_ques_safety_df['Question_mistral_safety'].apply(filter_safety_response).value_counts(normalize=True)\n",
    "        }).fillna(0).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Original Question -> Get Unsafe Original Question using LLama-Guard -> Response through all Models -> Labels from Llama Guard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_question_safety\n",
       "unsafe    0.932727\n",
       "safe      0.067273\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.original_question_safety.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>original_response_safety</th>\n",
       "      <th>safe</th>\n",
       "      <th>unsafe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>llama2</th>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.719298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3</th>\n",
       "      <td>0.130604</td>\n",
       "      <td>0.869396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama31</th>\n",
       "      <td>0.169591</td>\n",
       "      <td>0.830409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral</th>\n",
       "      <td>0.126706</td>\n",
       "      <td>0.873294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "original_response_safety      safe    unsafe\n",
       "model                                       \n",
       "llama2                    0.280702  0.719298\n",
       "llama3                    0.130604  0.869396\n",
       "llama31                   0.169591  0.830409\n",
       "mistral                   0.126706  0.873294"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtered unsafe original question according to llama guard\n",
    "data[data[\"original_question_safety\"] == \"unsafe\"].groupby(\"model\")[\"original_response_safety\"].value_counts(normalize=True).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Original Question -> Do Perturbation(char/word/sntnc) -> Check Safety of Perturbed Question -> Take only unsafe perturbed question -> Response through all Models -> Labels from Llama Guard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Safe percetnage of char, word, sentnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>perturbed_response_safety</th>\n",
       "      <th>safe</th>\n",
       "      <th>unsafe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perturbation_level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>char</th>\n",
       "      <td>0.181836</td>\n",
       "      <td>0.818164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sntnc</th>\n",
       "      <td>0.223295</td>\n",
       "      <td>0.776705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.815600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "perturbed_response_safety      safe    unsafe\n",
       "perturbation_level                           \n",
       "char                       0.181836  0.818164\n",
       "sntnc                      0.223295  0.776705\n",
       "word                       0.184400  0.815600"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Safety percentages for perturbed questions\n",
    "data[data[\"perturbed_question_safety\"] == \"unsafe\"].groupby(\"perturbation_level\").perturbed_response_safety.value_counts(normalize=True).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. re-verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char : 18.18\n",
      "word : 18.44\n",
      "sntnc : 22.33\n"
     ]
    }
   ],
   "source": [
    "for level in [\"char\",\"word\", \"sntnc\"]:\n",
    "    dd = data[data.perturbation_level == level]\n",
    "    dd = dd[dd.perturbed_question_safety == \"unsafe\"]\n",
    "    dd = dd.perturbed_response_safety.value_counts(normalize=True)*100\n",
    "    print(f\"{level} : {dd.safe:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Unsafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perturbed_response_safety</th>\n",
       "      <th>safe</th>\n",
       "      <th>unsafe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>perturbation_level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">llama2</th>\n",
       "      <th>char</th>\n",
       "      <td>28.177702</td>\n",
       "      <td>71.822298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sntnc</th>\n",
       "      <td>35.113636</td>\n",
       "      <td>64.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>29.150157</td>\n",
       "      <td>70.849843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">llama3</th>\n",
       "      <th>char</th>\n",
       "      <td>12.448323</td>\n",
       "      <td>87.551677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sntnc</th>\n",
       "      <td>18.295455</td>\n",
       "      <td>81.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>12.973084</td>\n",
       "      <td>87.026916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">llama31</th>\n",
       "      <th>char</th>\n",
       "      <td>16.444649</td>\n",
       "      <td>83.555351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sntnc</th>\n",
       "      <td>19.659091</td>\n",
       "      <td>80.340909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>16.074600</td>\n",
       "      <td>83.925400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">mistral</th>\n",
       "      <th>char</th>\n",
       "      <td>15.663757</td>\n",
       "      <td>84.336243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sntnc</th>\n",
       "      <td>16.250000</td>\n",
       "      <td>83.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>15.562235</td>\n",
       "      <td>84.437765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "perturbed_response_safety        safe     unsafe\n",
       "model   perturbation_level                      \n",
       "llama2  char                28.177702  71.822298\n",
       "        sntnc               35.113636  64.886364\n",
       "        word                29.150157  70.849843\n",
       "llama3  char                12.448323  87.551677\n",
       "        sntnc               18.295455  81.704545\n",
       "        word                12.973084  87.026916\n",
       "llama31 char                16.444649  83.555351\n",
       "        sntnc               19.659091  80.340909\n",
       "        word                16.074600  83.925400\n",
       "mistral char                15.663757  84.336243\n",
       "        sntnc               16.250000  83.750000\n",
       "        word                15.562235  84.437765"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"perturbed_question_safety\"] == \"unsafe\"].groupby([\"model\" , \"perturbation_level\"])[\"perturbed_response_safety\"].value_counts(normalize=True).unstack() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
