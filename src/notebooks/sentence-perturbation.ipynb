{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/szinjad/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/szinjad/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_sentence(sentence):\n",
    "    # Initialize models\n",
    "    paraphrase_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "    # Generate embeddings for the sentence\n",
    "    sentence_embedding = paraphrase_model.encode(sentence, convert_to_tensor=True)\n",
    "    \n",
    "    # Generate paraphrases\n",
    "    paraphrases = util.semantic_search(sentence_embedding, [sentence_embedding], top_k=5)\n",
    "    \n",
    "    # Return the top paraphrase (excluding the original sentence)\n",
    "    return paraphrases[0][1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def back_translate(sentence):\n",
    "    # Initialize models\n",
    "    translation_model_en_de = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-de')\n",
    "    translation_tokenizer_en_de = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-de')\n",
    "    translation_model_de_en = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-de-en')\n",
    "    translation_tokenizer_de_en = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-de-en')\n",
    "    \n",
    "    # Translate to German\n",
    "    de_tokens = translation_tokenizer_en_de(sentence, return_tensors=\"pt\", padding=True)\n",
    "    de_translation = translation_model_en_de.generate(**de_tokens)\n",
    "    de_text = translation_tokenizer_en_de.decode(de_translation[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Translate back to English\n",
    "    en_tokens = translation_tokenizer_de_en(de_text, return_tensors=\"pt\", padding=True)\n",
    "    en_translation = translation_model_de_en.generate(**en_tokens)\n",
    "    en_text = translation_tokenizer_de_en.decode(en_translation[0], skip_special_tokens=True)\n",
    "    \n",
    "    return en_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perturb_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    perturbed_sentences = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # Paraphrase\n",
    "        paraphrased = paraphrase_sentence(sentence)\n",
    "        perturbed_sentences.append((\"Paraphrase\", paraphrased))\n",
    "        \n",
    "        # Back-translate\n",
    "        back_translated = back_translate(sentence)\n",
    "        perturbed_sentences.append((\"Back-translation\", back_translated))\n",
    "    \n",
    "    return perturbed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/szinjad/.conda/envs/llm_safety_39/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m      3\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe quick brown fox jumps over the lazy dog. It was a beautiful day outside.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m perturbed_text \u001b[38;5;241m=\u001b[39m \u001b[43mperturb_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m perturbation_type, perturbed_sentence \u001b[38;5;129;01min\u001b[39;00m perturbed_text:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperturbation_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperturbed_sentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m, in \u001b[0;36mperturb_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m perturbed_sentences \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Paraphrase\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     paraphrased \u001b[38;5;241m=\u001b[39m \u001b[43mparaphrase_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     perturbed_sentences\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParaphrase\u001b[39m\u001b[38;5;124m\"\u001b[39m, paraphrased))\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Back-translate\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m, in \u001b[0;36mparaphrase_sentence\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      9\u001b[0m paraphrases \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39msemantic_search(sentence_embedding, [sentence_embedding], top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Return the top paraphrase (excluding the original sentence)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparaphrases\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "input_text = \"The quick brown fox jumps over the lazy dog. It was a beautiful day outside.\"\n",
    "perturbed_text = perturb_text(input_text)\n",
    "\n",
    "for perturbation_type, perturbed_sentence in perturbed_text:\n",
    "    print(f\"{perturbation_type}: {perturbed_sentence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
